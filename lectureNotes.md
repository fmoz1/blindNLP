# Advanced NLP 
## Intro 
1. Bidirectional RNN 
2. Seq2seq 
   *  Applications: machine translations, doesn't require input length to be equal to output length
3. Attention mechanism 
   * On top on seq2seq  
4. Memory networks 
   * Question asnwering 
   * Machine intelligence 
## Review: RNN, CNN
### Summary 
1. CNN
   * CNN most seen for images, RNN is the focus for texts 
   * CNNs are simpler, since they don't consider time, don't need recurrent connections, also they are faster 
2. RNN
   * All ML interfaces are the same  
### Word Embedding
1. NLP: machine learning applied to text/speech 
2. Feature vector (X1, X2, X3, ..., Xn)